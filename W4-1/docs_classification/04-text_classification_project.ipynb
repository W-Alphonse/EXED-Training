{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification pipeline: Application with text data\n",
    "\n",
    "Author: Alexandre Gramfort\n",
    "\n",
    "The objective of this hands on session is to setup a predictive pipeline to classify movie critics. Critics are either positive (y=1) or negative (y=0). This task is often referred to as **sentiment analysis**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you are being given :\n",
    "\n",
    "- critics of movies in text files in folder *data/imdb1*,\n",
    "\n",
    "Your mission :\n",
    "\n",
    "- Extract numeric features (the 'X') from the raw data (word counts)\n",
    "- Apply a Logistic Regression classifier with proper setup of hyperparameter\n",
    "- Evaluate performance in terms of accuracy with cross-validation\n",
    "- Answer the question \"Do I have enough data?\" using a learning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's load the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 documents\n",
      "Number of positives 1000 and negatives 1000\n"
     ]
    }
   ],
   "source": [
    "from glob import glob  # similar to --> ls *.txt \n",
    "filenames_neg = sorted(glob(op.join('data', 'imdb1', 'neg', '*.txt')))  # glob retorune list non retournée. 1 commentaire par fichier\n",
    "filenames_pos = sorted(glob(op.join('data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "# le fait d etre positif ou negatif correspond à un label qu'on a fabriquer par le code ci dessus \n",
    "\n",
    "print(\"%d documents\" % len(texts))\n",
    "print(\"Number of positives %s and negatives %s\" % (len(texts_pos), len(texts_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "- What does the array `y` correspond to?\n",
    "- What is the type of the variables `texts`?\n",
    "- Can you read the first text?\n",
    "- Complete the function **count_words** that counts the number of occurences of each word in a list of texts. You'll need to use the *split* method from the string class to split a text in words.\n",
    "\n",
    "Example of usage of the `split` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y contient des 0 et des 1\n",
    "type(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
      "what's the deal ? \n",
      "watch the movie and \" sorta \" find out . . . \n",
      "critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \n",
      "which is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn't snag this one correctly . \n",
      "they seem to have taken this pretty neat concept , but executed it terribly . \n",
      "so what are the problems with the movie ? \n",
      "well , its main problem is that it's simply too jumbled . \n",
      "it starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what's going on . \n",
      "there are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . \n",
      "now i personally don't mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film's biggest problem . \n",
      "it's obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . \n",
      "and do they make things entertaining , thrilling or even engaging , in the meantime ? \n",
      "not really . \n",
      "the sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn't the make the film all that more entertaining . \n",
      "i guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . \n",
      "i mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! \n",
      "okay , we get it . . . there \n",
      "are people chasing her and we don't know who they are . \n",
      "do we really need to see it over and over again ? \n",
      "how about giving us different scenes offering further insight into all of the strangeness going down in the movie ? \n",
      "apparently , the studio took this film away from its director and chopped it up themselves , and it shows . \n",
      "there might've been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . \n",
      "the actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . \n",
      "but my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character's unraveling . \n",
      "overall , the film doesn't stick because it doesn't entertain , it's confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . \n",
      "oh , and by the way , this is not a horror or teen slasher flick . . . it's \n",
      "just packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . \n",
      "it also wrapped production two years ago and has been sitting on the shelves ever since . \n",
      "whatever . . . skip \n",
      "it ! \n",
      "where's joblo coming from ? \n",
      "a nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot',\n",
       " ':',\n",
       " 'two',\n",
       " 'teen',\n",
       " 'couples',\n",
       " 'go',\n",
       " 'to',\n",
       " 'a',\n",
       " 'church',\n",
       " 'party',\n",
       " ',',\n",
       " 'drink',\n",
       " 'and',\n",
       " 'then',\n",
       " 'drive',\n",
       " '.',\n",
       " 'they',\n",
       " 'get',\n",
       " 'into',\n",
       " 'an',\n",
       " 'accident',\n",
       " '.',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'guys',\n",
       " 'dies',\n",
       " ',',\n",
       " 'but',\n",
       " 'his',\n",
       " 'girlfriend',\n",
       " 'continues',\n",
       " 'to',\n",
       " 'see',\n",
       " 'him',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life',\n",
       " ',',\n",
       " 'and',\n",
       " 'has',\n",
       " 'nightmares',\n",
       " '.',\n",
       " \"what's\",\n",
       " 'the',\n",
       " 'deal',\n",
       " '?',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'and',\n",
       " '\"',\n",
       " 'sorta',\n",
       " '\"',\n",
       " 'find',\n",
       " 'out',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'critique',\n",
       " ':',\n",
       " 'a',\n",
       " 'mind-fuck',\n",
       " 'movie',\n",
       " 'for',\n",
       " 'the',\n",
       " 'teen',\n",
       " 'generation',\n",
       " 'that',\n",
       " 'touches',\n",
       " 'on',\n",
       " 'a',\n",
       " 'very',\n",
       " 'cool',\n",
       " 'idea',\n",
       " ',',\n",
       " 'but',\n",
       " 'presents',\n",
       " 'it',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'bad',\n",
       " 'package',\n",
       " '.',\n",
       " 'which',\n",
       " 'is',\n",
       " 'what',\n",
       " 'makes',\n",
       " 'this',\n",
       " 'review',\n",
       " 'an',\n",
       " 'even',\n",
       " 'harder',\n",
       " 'one',\n",
       " 'to',\n",
       " 'write',\n",
       " ',',\n",
       " 'since',\n",
       " 'i',\n",
       " 'generally',\n",
       " 'applaud',\n",
       " 'films',\n",
       " 'which',\n",
       " 'attempt',\n",
       " 'to',\n",
       " 'break',\n",
       " 'the',\n",
       " 'mold',\n",
       " ',',\n",
       " 'mess',\n",
       " 'with',\n",
       " 'your',\n",
       " 'head',\n",
       " 'and',\n",
       " 'such',\n",
       " '(',\n",
       " 'lost',\n",
       " 'highway',\n",
       " '&',\n",
       " 'memento',\n",
       " ')',\n",
       " ',',\n",
       " 'but',\n",
       " 'there',\n",
       " 'are',\n",
       " 'good',\n",
       " 'and',\n",
       " 'bad',\n",
       " 'ways',\n",
       " 'of',\n",
       " 'making',\n",
       " 'all',\n",
       " 'types',\n",
       " 'of',\n",
       " 'films',\n",
       " ',',\n",
       " 'and',\n",
       " 'these',\n",
       " 'folks',\n",
       " 'just',\n",
       " \"didn't\",\n",
       " 'snag',\n",
       " 'this',\n",
       " 'one',\n",
       " 'correctly',\n",
       " '.',\n",
       " 'they',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'have',\n",
       " 'taken',\n",
       " 'this',\n",
       " 'pretty',\n",
       " 'neat',\n",
       " 'concept',\n",
       " ',',\n",
       " 'but',\n",
       " 'executed',\n",
       " 'it',\n",
       " 'terribly',\n",
       " '.',\n",
       " 'so',\n",
       " 'what',\n",
       " 'are',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'with',\n",
       " 'the',\n",
       " 'movie',\n",
       " '?',\n",
       " 'well',\n",
       " ',',\n",
       " 'its',\n",
       " 'main',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'that',\n",
       " \"it's\",\n",
       " 'simply',\n",
       " 'too',\n",
       " 'jumbled',\n",
       " '.',\n",
       " 'it',\n",
       " 'starts',\n",
       " 'off',\n",
       " '\"',\n",
       " 'normal',\n",
       " '\"',\n",
       " 'but',\n",
       " 'then',\n",
       " 'downshifts',\n",
       " 'into',\n",
       " 'this',\n",
       " '\"',\n",
       " 'fantasy',\n",
       " '\"',\n",
       " 'world',\n",
       " 'in',\n",
       " 'which',\n",
       " 'you',\n",
       " ',',\n",
       " 'as',\n",
       " 'an',\n",
       " 'audience',\n",
       " 'member',\n",
       " ',',\n",
       " 'have',\n",
       " 'no',\n",
       " 'idea',\n",
       " \"what's\",\n",
       " 'going',\n",
       " 'on',\n",
       " '.',\n",
       " 'there',\n",
       " 'are',\n",
       " 'dreams',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'characters',\n",
       " 'coming',\n",
       " 'back',\n",
       " 'from',\n",
       " 'the',\n",
       " 'dead',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'others',\n",
       " 'who',\n",
       " 'look',\n",
       " 'like',\n",
       " 'the',\n",
       " 'dead',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'strange',\n",
       " 'apparitions',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'disappearances',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'a',\n",
       " 'looooot',\n",
       " 'of',\n",
       " 'chase',\n",
       " 'scenes',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'tons',\n",
       " 'of',\n",
       " 'weird',\n",
       " 'things',\n",
       " 'that',\n",
       " 'happen',\n",
       " ',',\n",
       " 'and',\n",
       " 'most',\n",
       " 'of',\n",
       " 'it',\n",
       " 'is',\n",
       " 'simply',\n",
       " 'not',\n",
       " 'explained',\n",
       " '.',\n",
       " 'now',\n",
       " 'i',\n",
       " 'personally',\n",
       " \"don't\",\n",
       " 'mind',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'unravel',\n",
       " 'a',\n",
       " 'film',\n",
       " 'every',\n",
       " 'now',\n",
       " 'and',\n",
       " 'then',\n",
       " ',',\n",
       " 'but',\n",
       " 'when',\n",
       " 'all',\n",
       " 'it',\n",
       " 'does',\n",
       " 'is',\n",
       " 'give',\n",
       " 'me',\n",
       " 'the',\n",
       " 'same',\n",
       " 'clue',\n",
       " 'over',\n",
       " 'and',\n",
       " 'over',\n",
       " 'again',\n",
       " ',',\n",
       " 'i',\n",
       " 'get',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'fed',\n",
       " 'up',\n",
       " 'after',\n",
       " 'a',\n",
       " 'while',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'this',\n",
       " \"film's\",\n",
       " 'biggest',\n",
       " 'problem',\n",
       " '.',\n",
       " \"it's\",\n",
       " 'obviously',\n",
       " 'got',\n",
       " 'this',\n",
       " 'big',\n",
       " 'secret',\n",
       " 'to',\n",
       " 'hide',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'want',\n",
       " 'to',\n",
       " 'hide',\n",
       " 'it',\n",
       " 'completely',\n",
       " 'until',\n",
       " 'its',\n",
       " 'final',\n",
       " 'five',\n",
       " 'minutes',\n",
       " '.',\n",
       " 'and',\n",
       " 'do',\n",
       " 'they',\n",
       " 'make',\n",
       " 'things',\n",
       " 'entertaining',\n",
       " ',',\n",
       " 'thrilling',\n",
       " 'or',\n",
       " 'even',\n",
       " 'engaging',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'meantime',\n",
       " '?',\n",
       " 'not',\n",
       " 'really',\n",
       " '.',\n",
       " 'the',\n",
       " 'sad',\n",
       " 'part',\n",
       " 'is',\n",
       " 'that',\n",
       " 'the',\n",
       " 'arrow',\n",
       " 'and',\n",
       " 'i',\n",
       " 'both',\n",
       " 'dig',\n",
       " 'on',\n",
       " 'flicks',\n",
       " 'like',\n",
       " 'this',\n",
       " ',',\n",
       " 'so',\n",
       " 'we',\n",
       " 'actually',\n",
       " 'figured',\n",
       " 'most',\n",
       " 'of',\n",
       " 'it',\n",
       " 'out',\n",
       " 'by',\n",
       " 'the',\n",
       " 'half-way',\n",
       " 'point',\n",
       " ',',\n",
       " 'so',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'strangeness',\n",
       " 'after',\n",
       " 'that',\n",
       " 'did',\n",
       " 'start',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'sense',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'still',\n",
       " \"didn't\",\n",
       " 'the',\n",
       " 'make',\n",
       " 'the',\n",
       " 'film',\n",
       " 'all',\n",
       " 'that',\n",
       " 'more',\n",
       " 'entertaining',\n",
       " '.',\n",
       " 'i',\n",
       " 'guess',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'with',\n",
       " 'movies',\n",
       " 'like',\n",
       " 'this',\n",
       " 'is',\n",
       " 'that',\n",
       " 'you',\n",
       " 'should',\n",
       " 'always',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'that',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'is',\n",
       " '\"',\n",
       " 'into',\n",
       " 'it',\n",
       " '\"',\n",
       " 'even',\n",
       " 'before',\n",
       " 'they',\n",
       " 'are',\n",
       " 'given',\n",
       " 'the',\n",
       " 'secret',\n",
       " 'password',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'your',\n",
       " 'world',\n",
       " 'of',\n",
       " 'understanding',\n",
       " '.',\n",
       " 'i',\n",
       " 'mean',\n",
       " ',',\n",
       " 'showing',\n",
       " 'melissa',\n",
       " 'sagemiller',\n",
       " 'running',\n",
       " 'away',\n",
       " 'from',\n",
       " 'visions',\n",
       " 'for',\n",
       " 'about',\n",
       " '20',\n",
       " 'minutes',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'is',\n",
       " 'just',\n",
       " 'plain',\n",
       " 'lazy',\n",
       " '!',\n",
       " '!',\n",
       " 'okay',\n",
       " ',',\n",
       " 'we',\n",
       " 'get',\n",
       " 'it',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'there',\n",
       " 'are',\n",
       " 'people',\n",
       " 'chasing',\n",
       " 'her',\n",
       " 'and',\n",
       " 'we',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'who',\n",
       " 'they',\n",
       " 'are',\n",
       " '.',\n",
       " 'do',\n",
       " 'we',\n",
       " 'really',\n",
       " 'need',\n",
       " 'to',\n",
       " 'see',\n",
       " 'it',\n",
       " 'over',\n",
       " 'and',\n",
       " 'over',\n",
       " 'again',\n",
       " '?',\n",
       " 'how',\n",
       " 'about',\n",
       " 'giving',\n",
       " 'us',\n",
       " 'different',\n",
       " 'scenes',\n",
       " 'offering',\n",
       " 'further',\n",
       " 'insight',\n",
       " 'into',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'strangeness',\n",
       " 'going',\n",
       " 'down',\n",
       " 'in',\n",
       " 'the',\n",
       " 'movie',\n",
       " '?',\n",
       " 'apparently',\n",
       " ',',\n",
       " 'the',\n",
       " 'studio',\n",
       " 'took',\n",
       " 'this',\n",
       " 'film',\n",
       " 'away',\n",
       " 'from',\n",
       " 'its',\n",
       " 'director',\n",
       " 'and',\n",
       " 'chopped',\n",
       " 'it',\n",
       " 'up',\n",
       " 'themselves',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'shows',\n",
       " '.',\n",
       " 'there',\n",
       " \"might've\",\n",
       " 'been',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'decent',\n",
       " 'teen',\n",
       " 'mind-fuck',\n",
       " 'movie',\n",
       " 'in',\n",
       " 'here',\n",
       " 'somewhere',\n",
       " ',',\n",
       " 'but',\n",
       " 'i',\n",
       " 'guess',\n",
       " '\"',\n",
       " 'the',\n",
       " 'suits',\n",
       " '\"',\n",
       " 'decided',\n",
       " 'that',\n",
       " 'turning',\n",
       " 'it',\n",
       " 'into',\n",
       " 'a',\n",
       " 'music',\n",
       " 'video',\n",
       " 'with',\n",
       " 'little',\n",
       " 'edge',\n",
       " ',',\n",
       " 'would',\n",
       " 'make',\n",
       " 'more',\n",
       " 'sense',\n",
       " '.',\n",
       " 'the',\n",
       " 'actors',\n",
       " 'are',\n",
       " 'pretty',\n",
       " 'good',\n",
       " 'for',\n",
       " 'the',\n",
       " 'most',\n",
       " 'part',\n",
       " ',',\n",
       " 'although',\n",
       " 'wes',\n",
       " 'bentley',\n",
       " 'just',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'playing',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'same',\n",
       " 'character',\n",
       " 'that',\n",
       " 'he',\n",
       " 'did',\n",
       " 'in',\n",
       " 'american',\n",
       " 'beauty',\n",
       " ',',\n",
       " 'only',\n",
       " 'in',\n",
       " 'a',\n",
       " 'new',\n",
       " 'neighborhood',\n",
       " '.',\n",
       " 'but',\n",
       " 'my',\n",
       " 'biggest',\n",
       " 'kudos',\n",
       " 'go',\n",
       " 'out',\n",
       " 'to',\n",
       " 'sagemiller',\n",
       " ',',\n",
       " 'who',\n",
       " 'holds',\n",
       " 'her',\n",
       " 'own',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'film',\n",
       " ',',\n",
       " 'and',\n",
       " 'actually',\n",
       " 'has',\n",
       " 'you',\n",
       " 'feeling',\n",
       " 'her',\n",
       " \"character's\",\n",
       " 'unraveling',\n",
       " '.',\n",
       " 'overall',\n",
       " ',',\n",
       " 'the',\n",
       " 'film',\n",
       " \"doesn't\",\n",
       " 'stick',\n",
       " 'because',\n",
       " 'it',\n",
       " \"doesn't\",\n",
       " 'entertain',\n",
       " ',',\n",
       " \"it's\",\n",
       " 'confusing',\n",
       " ',',\n",
       " 'it',\n",
       " 'rarely',\n",
       " 'excites',\n",
       " 'and',\n",
       " 'it',\n",
       " 'feels',\n",
       " 'pretty',\n",
       " 'redundant',\n",
       " 'for',\n",
       " 'most',\n",
       " 'of',\n",
       " 'its',\n",
       " 'runtime',\n",
       " ',',\n",
       " 'despite',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'cool',\n",
       " 'ending',\n",
       " 'and',\n",
       " 'explanation',\n",
       " 'to',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'craziness',\n",
       " 'that',\n",
       " 'came',\n",
       " 'before',\n",
       " 'it',\n",
       " '.',\n",
       " 'oh',\n",
       " ',',\n",
       " 'and',\n",
       " 'by',\n",
       " 'the',\n",
       " 'way',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'horror',\n",
       " 'or',\n",
       " 'teen',\n",
       " 'slasher',\n",
       " 'flick',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " \"it's\",\n",
       " 'just',\n",
       " 'packaged',\n",
       " 'to',\n",
       " 'look',\n",
       " 'that',\n",
       " 'way',\n",
       " 'because',\n",
       " 'someone',\n",
       " 'is',\n",
       " 'apparently',\n",
       " 'assuming',\n",
       " 'that',\n",
       " 'the',\n",
       " 'genre',\n",
       " 'is',\n",
       " 'still',\n",
       " 'hot',\n",
       " 'with',\n",
       " 'the',\n",
       " 'kids',\n",
       " '.',\n",
       " 'it',\n",
       " 'also',\n",
       " 'wrapped',\n",
       " 'production',\n",
       " 'two',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'has',\n",
       " 'been',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'the',\n",
       " 'shelves',\n",
       " 'ever',\n",
       " 'since',\n",
       " '.',\n",
       " 'whatever',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'skip',\n",
       " 'it',\n",
       " '!',\n",
       " \"where's\",\n",
       " 'joblo',\n",
       " 'coming',\n",
       " 'from',\n",
       " '?',\n",
       " 'a',\n",
       " 'nightmare',\n",
       " 'of',\n",
       " 'elm',\n",
       " 'street',\n",
       " '3',\n",
       " '(',\n",
       " '7/10',\n",
       " ')',\n",
       " '-',\n",
       " 'blair',\n",
       " 'witch',\n",
       " '2',\n",
       " '(',\n",
       " '7/10',\n",
       " ')',\n",
       " '-',\n",
       " 'the',\n",
       " 'crow',\n",
       " '(',\n",
       " '9/10',\n",
       " ')',\n",
       " '-',\n",
       " 'the',\n",
       " 'crow',\n",
       " ':',\n",
       " 'salvation',\n",
       " '(',\n",
       " '4/10',\n",
       " ')',\n",
       " '-',\n",
       " 'lost',\n",
       " 'highway',\n",
       " '(',\n",
       " '10/10',\n",
       " ')',\n",
       " '-',\n",
       " 'memento',\n",
       " '(',\n",
       " '10/10',\n",
       " ')',\n",
       " '-',\n",
       " 'the',\n",
       " 'others',\n",
       " '(',\n",
       " '9/10',\n",
       " ')',\n",
       " '-',\n",
       " 'stir',\n",
       " 'of',\n",
       " 'echoes',\n",
       " '(',\n",
       " '8/10',\n",
       " ')']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_text = texts[0]\n",
    "this_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'DSSP', 'attendees!']\n",
      "number of words : 3\n"
     ]
    }
   ],
   "source": [
    "words = \"Hello DSSP attendees!\".split()\n",
    "print(words)\n",
    "print(\"number of words : %s\" % len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of usage of the `count_words` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">>> some_texts = ['A B B', 'B', 'A A']\n",
    ">>> vocabulary, counts = count_words(some_texts)\n",
    ">>> print(vocabulary)  # dictionary word -> column index\n",
    "{'A': 0, 'B': 1}\n",
    ">>> print(counts)  # number of occurence of each word from vocabulary in each text\n",
    "[[ 1.  2.]\n",
    " [ 0.  1.]\n",
    " [ 2.  0.]]\n",
    "```\n",
    "\n",
    "**Remark:** The vocabularty is a `dict` and its values have nothing to do with a number of occurences. Its values are the indices of columns in the `counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(texts):\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    # Strat 1\n",
    "    if 0:\n",
    "        vocabulary = dict()\n",
    "        n_words = 0\n",
    "        for text in texts:\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = n_words\n",
    "                    n_words += 1\n",
    "    # Strat 2\n",
    "    all_words = []\n",
    "    for text in texts:\n",
    "        all_words += text.split()\n",
    "    unique_words = np.unique(all_words)\n",
    "    vocabulary = dict()\n",
    "    n_words = 0\n",
    "    for w in unique_words:\n",
    "        vocabulary[w] = n_words\n",
    "        n_words += 1\n",
    "    counts = \n",
    "#    vocabulary = None\n",
    "    return vocabulary, counts\n",
    "some_texts = ['A B B', 'B', 'A A']\n",
    "count_words(some_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 50920)\n",
      "1492681\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def count_words(texts):\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    vocabulary = dict()\n",
    "    word_index = 0\n",
    "    \n",
    "    # Build the dictionary resulting from all texts\n",
    "    for current_text in range(len(texts)) :\n",
    "        words = texts[current_text].split()\n",
    "        # Build the dictionary resulting from a single text\n",
    "        for any_word in words:\n",
    "            if any_word not in vocabulary.keys() :\n",
    "                vocabulary[any_word] = word_index\n",
    "                word_index += 1\n",
    "    \n",
    "    # Build the np.array(i -> text number, j -> occurence count of vocabulary.get(word) )  \n",
    "    counts = np.zeros((len(texts), len(vocabulary)), dtype=np.int32)\n",
    "    for current_text in range(len(texts)) :\n",
    "        words = texts[current_text].split()\n",
    "        for any_word in words:\n",
    "            counts[current_text, vocabulary.get(any_word) ] += 1\n",
    "\n",
    "        \n",
    "    # TODO\n",
    "    return vocabulary, counts\n",
    "\n",
    "vocabulary, counts = count_words(texts)\n",
    "print(counts.shape)\n",
    "print(counts.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Estimate Logistic regression on the full data. Show the effect of overfitting by evaluating the predictive power of your method in terms of accuracy.\n",
    "- Use the `train_test_split` function split the data in train and test (80% train and 20% test). What performance do you get?\n",
    "- Can you do better by adjusting the regularization parameter C? Use values between 0.00001 and 1000.\n",
    "- Why is this potentially dangerous? How do you avoid troubles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#clf = LogisticRegression(C=1.)\n",
    "clf = LogisticRegression(solver='liblinear', C=1.)  \n",
    "# C correspond à la regularization. Elle empeche le modèle d'avoir trop de paramètres de libertes, cà d trop de variance.\n",
    "# Pour limiter cette variance, il faut la biaiser, càd ajouter un param de regularization\n",
    "#\n",
    "# Regularization technique is based on the fact that if the highest order terms in a polynomial equation have very small coefficients, \n",
    "# then the function will approximately behave like a polynomial function of a smaller degree.\n",
    "\n",
    "clf.fit(counts, y)\n",
    "np.mean(clf.predict(counts) == y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.845"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "\n",
    "# TODO : Use the train_test_split function split the data in train and test (80% train and 20% test). What performance do you get?\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, y, train_size=0.8, random_state=0)\n",
    "clf = LogisticRegression(solver = 'liblinear',C=1.)\n",
    "clf.fit(X_train,y_train)\n",
    "np.mean(clf.predict(X_test)==y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C : 1e-05 - Score : 0.585\n",
      "C : 0.0001 - Score : 0.6625\n",
      "C : 0.001 - Score : 0.765\n",
      "C : 0.01 - Score : 0.8175\n",
      "C : 0.1 - Score : 0.8275\n",
      "C : 1.0 - Score : 0.8225\n",
      "C : 10.0 - Score : 0.82\n",
      "C : 100.0 - Score : 0.82\n",
      "C : 1000.0 - Score : 0.8175\n",
      "-----------------\n",
      "Best C : 0.1 - Best Score : 0.8275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Can you do better by adjusting the regularization parameter C? Use values between 0.00001 and 1000\n",
    "# log(10) = 1 / log(1000) = 3 / log(10 puiss n) = n  / log(0.1) = -1 / ...\n",
    "Cs = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1., 10., 100., 1000.]\n",
    "scores = []\n",
    "for C in Cs:\n",
    "    clf.C = C\n",
    "    score = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "    print('C : %s - Score : %s' % (C, score))\n",
    "\n",
    "print('-----------------')\n",
    "C_best = Cs[np.argmax(scores)]\n",
    "print('Best C : %s - Best Score : %s' % (C_best, np.max(scores)))\n",
    "plt.plot(np.log10(Cs), scores)\n",
    "plt.axvline(np.log10(C_best), color='k')\n",
    "plt.xlabel(\"log10(C)\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(counts, y, train_size=0.8, random_state=None)\n",
    "clf.C = 0.01\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Compare the performance of Logistic Regression vs Multinomial Nayes Bayes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Compare your implementation of word counting with scikit-learn.\n",
    "\n",
    "For this use the classes *CountVectorizer* and a *Pipeline*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score  # replace by cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.75, ngram_range=(1, 1),\n",
    "                             analyzer='word', stop_words=None)),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Could do you better with more data? Is the model complex too complex or too simple? Hint: Use a learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Can you do better using bigrams? Use parameter `ngram_range=(1, 2)` in CountVectorizer\n",
    "- Compare the learning curves using single words or bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.75, ngram_range=(1, 2),\n",
    "                             analyzer='word', stop_words=None)),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
